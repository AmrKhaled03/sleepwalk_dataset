# -*- coding: utf-8 -*-
"""SleepWell.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SdtgiNRRZBtIZzmLZWJWah055277VXff
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Load the dataset
file_path = '/content/Sleep_health_and_lifestyle_dataset.csv'
data = pd.read_csv(file_path)

# Show the original shape of the dataset
print(f"Original shape of the dataset: {data.shape}")

# Show the first few rows of the dataset
print(data.head())

# Check for missing values in the dataset
print("Missing values in each column:")
print(data.isnull().sum())

# Check unique values in categorical columns
print("Unique values in 'Gender' column:", data['Gender'].unique())
print("Unique values in 'Sleep Disorder' column:", data['Sleep Disorder'].unique())

# Preprocessing: Convert categorical data to numerical
data['Gender'] = data['Gender'].map({'Male': 0, 'Female': 1})

# Map sleep disorders to numerical values
data['Sleep Disorder'] = data['Sleep Disorder'].map({'Sleep Apnea': 1, 'Insomnia': 2})

# Check if any values were not mapped correctly (NaNs after mapping)
print("Missing values after mapping:")
print(data.isnull().sum())

# Drop rows where Sleep Disorder is NaN
data.dropna(subset=['Sleep Disorder'], inplace=True)

# Print the shape of the dataset after dropping missing values
print(f"Shape of the dataset after dropping missing values: {data.shape}")

# Selecting input features and target variable
X = data[['Sleep Duration', 'Physical Activity Level', 'Stress Level', 'Age', 'Gender']]
y = data['Sleep Disorder']

# Check for NaN values in the target variable
print("NaN values in target variable (y):", y.isnull().sum())  # Should print 0

# Check the shapes of X and y
print(f"Shape of X: {X.shape}, Shape of y: {y.shape}")

# Ensure that we have enough samples
if X.shape[0] == 0 or y.shape[0] == 0:
    raise ValueError("X or y is empty. Please check your dataset for preprocessing issues.")

# Splitting the dataset into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalize the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Build and train a Logistic Regression model
model = LogisticRegression()
model.fit(X_train, y_train)

# Predict on the test set
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Test Accuracy: {accuracy * 100:.2f}%")
print(classification_report(y_test, y_pred))

# Additional Visualizations
# 1. Visualizing the distribution of features

# 1. Visualizing the distribution of features
for column in X.columns:
    plt.figure(figsize=(10, 5))
    sns.histplot(data[column], bins=30, kde=True)
    plt.title(f'Distribution of {column}')
    plt.xlabel(column)
    plt.ylabel('Frequency')
    plt.show()

# 2. Correlation matrix
plt.figure(figsize=(8, 6))
# Selecting only numeric columns for correlation matrix
numeric_data = data.select_dtypes(include=['float64', 'int64'])
correlation_matrix = numeric_data.corr()
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm', square=True)
plt.title('Correlation Matrix')
plt.show()

# 3. Coefficients visualization
coefficients = model.coef_[0]
features = X.columns
plt.figure(figsize=(10, 5))
sns.barplot(x=features, y=coefficients)
plt.title('Logistic Regression Coefficients')
plt.xlabel('Features')
plt.ylabel('Coefficient Value')
plt.xticks(rotation=45)
plt.show()


# 3. Coefficients visualization
coefficients = model.coef_[0]
features = X.columns
plt.figure(figsize=(10, 5))
sns.barplot(x=features, y=coefficients)
plt.title('Logistic Regression Coefficients')
plt.xlabel('Features')
plt.ylabel('Coefficient Value')
plt.xticks(rotation=45)
plt.show()





pip install tensorflow

!pip install numpy==1.24.3
!pip install --upgrade tensorflow

!pip install --upgrade tensorflow

pip uninstall numpy

!pip uninstall numpy

pip install numpy==1.26.0

!pip uninstall tensorflow -y
!pip install tensorflow==2.17.0

!pip uninstall tf-keras -y
!pip install tf-keras

import numpy as np
import tensorflow as tf

print("NumPy version:", np.__version__)
print("TensorFlow version:", tf.__version__)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow import keras
from tensorflow.keras import layers

# Load your dataset
data = pd.read_csv('/content/Sleep_health_and_lifestyle_dataset.csv')

# Check for null values
print("Null values in each column:")
print(data.isnull().sum())

# Check the data types of the features and target
print("\nData types of the columns:")
print(data.dtypes)

# Check unique values in the target to ensure it's binary or categorical
print("\nUnique values in 'Sleep Disorder':")
print(data['Sleep Disorder'].unique())

# Handle null values by removing rows with NaN values
data = data.dropna()

# Convert specific columns to numeric, if they are not already
data['Sleep Duration'] = pd.to_numeric(data['Sleep Duration'], errors='coerce')
data['Physical Activity Level'] = pd.to_numeric(data['Physical Activity Level'], errors='coerce')
data['Stress Level'] = pd.to_numeric(data['Stress Level'], errors='coerce')
data['Age'] = pd.to_numeric(data['Age'], errors='coerce')
data['Sleep Disorder'] = pd.to_numeric(data['Sleep Disorder'], errors='coerce')

# Check again for null values after conversion
print("\nNull values after conversion:")
print(data.isnull().sum())

# Split data into features (X) and target (y)
X = data[['Sleep Duration', 'Physical Activity Level', 'Stress Level', 'Age']]
y = data['Sleep Disorder']  # Binary or categorical values

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Create and train your model
model = keras.Sequential([
    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    layers.Dense(32, activation='relu'),
    layers.Dense(1, activation='sigmoid')  # For binary classification
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Fit the model
model.fit(X_train, y_train, epochs=10, batch_size=32)

# Save your model
model.save('insomnia_model.h5')

# Load the saved model
loaded_model = keras.models.load_model('insomnia_model.h5')

# Make predictions using the loaded model
new_predictions = loaded_model.predict(X_test)

# Convert predictions to binary outcomes
predicted_classes = (new_predictions > 0.5).astype("int32")

# Compare predictions with actual values
comparison = pd.DataFrame({'Actual': y_test, 'Predicted': predicted_classes.flatten()})
print(comparison.head())

# Define your labels based on your model's outputs
labels = ["No Insomnia", "Mild Insomnia", "Moderate Insomnia", "Severe Insomnia"]  # Example labels

# Specify the path for the labels file
labels_path = '/content/insomnia_labels.txt'

# Ensure the directory exists
os.makedirs(os.path.dirname(labels_path), exist_ok=True)

# Save the labels to a .txt file
with open(labels_path, 'w') as f:
    for label in labels:
        f.write(f"{label}\n")

print(f"Labels have been created and saved to {labels_path}.")

import tensorflow as tf
import os


# Check the current working directory
print("Current Working Directory:", os.getcwd())

# Load your existing model
model = tf.keras.models.load_model('/content/insomnia_model.h5')

# Convert the model to TFLite format
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save the TFLite model
with open('insomnia_model.tflite', 'wb') as f:
    f.write(tflite_model)

# Specify the correct path to the labels
labels_path = '/content/insomnia_labels.txt'  # Update this if necessary
try:
    with open(labels_path, 'r') as file:
        labels = file.readlines()

    # Clean up the labels by removing any whitespace characters
    labels = [label.strip() for label in labels]

    # Save the labels to a .txt file for future reference
    with open('insomnia_labels_processed.txt', 'w') as f:
        for label in labels:
            f.write(f"{label}\n")

    print("Model and labels have been successfully saved!")

except FileNotFoundError:
    print(f"Error: The file {labels_path} does not exist. Please check the path.")